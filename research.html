<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>M. S. B. Siddiqui - Research</title>
    <!-- CSS Links etc. -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <!-- Final Navigation Bar -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top">
        <div class="container">
            <a class="navbar-brand" href="index.html">M. S. B. Siddiqui</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item"><a class="nav-link" href="index.html">About</a></li>
                    <li class="nav-item"><a class="nav-link active" href="research.html">Research</a></li>
                    <li class="nav-item"><a class="nav-link" href="publications.html">Publications</a></li>
                    <li class="nav-item"><a class="nav-link" href="teaching.html">Teaching</a></li>
                    <li class="nav-item"><a class="nav-link" href="experience.html">Experience</a></li>
                    <li class="nav-item"><a class="nav-link" href="qualifications.html">Credentials</a></li>
                    <li class="nav-item"><a class="nav-link" href="awards.html">Awards</a></li>
                    <li class="nav-item"><a class="nav-link" href="others.html">Others</a></li>
                </ul>
                <button id="theme-toggle" class="btn theme-toggle-btn ms-2">
                    <i class="fas fa-moon"></i>
                </button>
            </div>
        </div>
    </nav>

    <!-- Main Content -->
    <main>
        <section id="research" class="section fade-in">
            <div class="container">
                <h2 class="mb-5">Research</h2>

                <!-- Research Statement -->
                <h3 class="text-center mb-4">Research Statement</h3>
                <p class="lead">My research is centered at the intersection of Deep Learning, Signal Processing, and Computer Vision, with a primary focus on developing ML-based solutions for Healthcare and Diagnostics. I am driven by the challenge of fusing information from multiple signal representations to build models that are more efficient, generalizable, and interpretable than their unimodal counterparts.</p>
                <p>Solving mathematical and scientific problems was my passion from early days, and it also happened to be my strength. That’s why I chose engineering. Signal Processing was something I really started to enjoy. In my eyes, the frequency domain was a whole new universe, and to this day, the fascination is intact. During the COVID-19 lockdown, I got to explore Machine Learning and Deep Learning in depth through multiple online specializations. The fundamentals of ML & DL intrigued me, and soon, I knew I had found my field of interest. After graduation, I consciously chose to enroll in two MS programs (CS, EE) simultaneously. I focused on solidifying my uderstanding of core DL and also explored its applications, leveraging the two simultaneous programs.</p>
                <p>My background is rooted in classical Electrical Engineering (Signal Processing to be specific!). I enjoy bridging that foundational knowledge with the fast-paced world of modern deep learning. Due to my multidisciplinary background, I have quite a wide range of research interests, spanning from Multi-Modal Machine Learning & Deep Learning Architectures, to their applications in Biomedical Imaging, Signal Processing, Bioinformatics and even Computational Social Science. My research (at the moment) revolves around developing deep-learning frameworks that efficiently learn from multiple signal representations simultaneously, leveraging multi-modal fusion based architectures. The focus is on techniques that can effectively fuse features extracted from time/spatial and frequency/spectral domain representations, building models that are more efficient, due to the simultaneous learning from the different perspectives of the data provided by the complementary domains. I have explored this approach in multiple domains like Biomedical Imaging (Images + their FFTs) and Audio Analysis (Waveforms + Spectrograms).</p>
                <p>I also very much enjoy tweaking and tuning Deep Learning architectures based on my intuitions. Even though intution doesn't always work with Neural networks, I found theoretically grounded insights to be quite useful. I am also ineterested in more theoretical aspects of Deep Learning, like Generalization, and worked on it for my MS thesis.</p>
                <p>To that end, I recently co-founded an ad-hoc research group with a few other young researchers from Bangladesh, called <strong>BIOML (Bioinformatics, Imaging & Omics using Machine Learning)</strong>. Our goal is to foster collaborative, open research. Some areas our current work covers include multi-modal fusion for biomedical audio, advanced methods for Antimicrobial Resistance (AMR) prediction, and developing novel deep learning frameworks for medical imaging.</p>
                <p>If any of this sounds interesting, or if you'd like to collaborate, please feel free to send me an email!</p>
                <p class="mb-5">A significant portion of my work is dedicated to applications in the biomedical domain, including diagnostic imaging, bioinformatics, and the analysis of physiological signals. I am passionate about creating technologies that can lead to tangible improvements in healthcare. Concurrently, I explore the application of these computational methods to analyze complex socio-political systems, aiming to uncover data-driven insights into human behavior. My ultimate goal is to advance the frontier of multi-modal AI and apply it to solve meaningful, real-world problems through collaborative and open research.</p>

                <!-- Research Interests -->
                <h3 class="text-center mb-4">Research Interests</h3>
                <div class="row mb-5">
                    <div class="col-md-6">
                        <ul class="list-unstyled specializations">
                            <li><i class="fas fa-project-diagram"></i> Multi-Modal Machine Learning</li>
                            <li><i class="fas fa-brain"></i> Deep Learning Architectures</li>
                            <li><i class="fas fa-wave-square"></i> Signal & Image Processing</li>
                            <li><i class="fas fa-microphone-alt"></i> Audio and Speech Processing</li>
                            <li><i class="fas fa-sitemap"></i> Federated Learning</li>
                        </ul>
                    </div>
                    <div class="col-md-6">
                        <ul class="list-unstyled specializations">
                            <li><i class="fas fa-eye"></i> Computer Vision and Medical Imaging</li>
                            <li><i class="fas fa-dna"></i> Bioinformatics</li>
                            <li><i class="fas fa-heartbeat"></i> AI in Healthcare</li>
                            <li><i class="fas fa-landmark"></i> Computational Social Science</li>
                            <li><i class="fas fa-microscope"></i> Explainable AI</li>
                        </ul>
                    </div>
                </div>

                <!-- Thesis Projects -->
                <h3 class="text-center mb-4">Thesis Projects</h3>
                <div class="card mb-4">
                    <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="DUA_D2C.png" class="img-fluid rounded" alt="D2C Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">M.Sc. Thesis (CSE)</span>
                                <h4 class="card-title text-primary">Divide2Conquer (D2C) & Dynamic Uncertainty Aware Divide2Conquer (DUA-D2C): Overfitting Remediation in Deep Learning Using a Decentralized Approach</h4>
                                <p class="text-muted"><strong>Supervisor:</strong> Prof. Dr. Golam Rabiul Alam</p>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Deep Learning</span>
                                    <span class="badge rounded-pill bg-primary">Overfitting</span>
                                    <span class="badge rounded-pill bg-primary">Optimization</span>
                                </div>
                                <hr>
                                <p><strong>Part 1 (D2C):</strong> Introduced the Divide2Conquer (D2C) method, which partitions training data to train simpler models independently, aggregating parameters periodically to mitigate overfitting and improve generalization. Published at IEEE BigData 2024.</p>
                                <div class="mb-3">
                                    <a href="https://doi.org/10.1109/BigData62323.2024.10826082" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt me-1"></i> Paper</a>
                                    <a href="https://github.com/Saiful185/Divide2Conquer" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github me-1"></i> Code</a>
                                </div>
                                <p><strong>Part 2 (DUA-D2C Extension):</strong> Developed Dynamic Uncertainty-Aware D2C, an enhancement that dynamically weights subset models based on performance and prediction uncertainty, further improving robustness. Currently under review.</p>
                                <div>
                                    <a href="https://arxiv.org/abs/2411.15876" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt me-1"></i> Preprint</a>
                                    <a href="https://github.com/Saiful185/DUA-D2C" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github me-1"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="card mb-4">
                     <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="S3FNet_SN1.png" class="img-fluid rounded" alt="S3F-Net Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">M.Sc. Thesis (EEE)</span>
                                <h4 class="card-title text-primary">Medical Image Segmentation & Classification based on a Dual-Domain Approach of Spatial and Spectral Feature Fusion</h4>
                                <p class="text-muted"><strong>Supervisor:</strong> Prof. Dr. Mohammed Imamul Hassan Bhuiyan</p>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Computer Vision</span>
                                    <span class="badge rounded-pill bg-primary me-1">Biomedical Imaging</span>
                                    <span class="badge rounded-pill bg-primary">Representation Learning</span>
                                    <span class="badge rounded-pill bg-primary">Multi-Modal Fusion</span>
                                </div>
                                <hr>
                                <p><strong>Part 1 (S³F-Net for Image Classification):</strong> Proposed S³F-Net, a dual-branch framework that learns from both spatial (CNN) and spectral (SpectraNet) domains simultaneously, achieving state-of-the-art competitive accuracy on multiple medical imaging datasets.</p>
                                <div class="mb-3">
                                    <a href="https://arxiv.org/abs/2509.23442" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt me-1"></i> Preprint</a>
                                    <a href="https://github.com/Saiful185/S3F-Net" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github me-1"></i> Code</a>
                                </div>
                                <p><strong>Part 2 (Medical Image Segmentation):</strong> Currently extending the S³F-Net architecture to perform robust and accurate segmentation tasks on medical images, leveraging its dual-domain feature learning capabilities.</p>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="card mb-5">
                     <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="BRL_RF.JPG" class="img-fluid rounded" alt="BRL Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">B.Sc. Thesis (EEE)</span>
                                <h4 class="card-title text-primary">Bioradiolocation-Based Multi-Class Sleep Stage Classification</h4>
                                <p class="text-muted"><strong>Supervisor:</strong> Prof. Dr. Mohammed Imamul Hassan Bhuiyan</p>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Biomedical Signal Processing</span>
                                    <span class="badge rounded-pill bg-primary">Machine Learning</span>
                                </div>
                                <hr>
                                <p>This undergraduate thesis focused on a non-invasive sleep stage classification method using bioradiolocation signals. By extracting time-frequency features and employing a Random Forest classifier, the system achieved high accuracy comparable to state-of-the-art methods, published at ICECE 2022.</p>
                                <div>
                                    <a href="https://doi.org/10.1109/ICECE57408.2022.10089093" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt me-1"></i> Paper</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Ongoing Research Projects -->
                <h3 class="text-center mb-4">Ongoing Research Projects</h3>
                <div class="card mb-4">
                     <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="July_Revolution.JPG" class="img-fluid rounded" alt="July Revolution Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">Collaboration with University of Oxford</span>
                                <h4 class="card-title text-primary">Machine Learning & Statistical Modeling Driven Repression and Mobilization Analysis of Bangladesh's Social Movements</h4>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Computational Social Science</span>
                                    <span class="badge rounded-pill bg-primary">Statistical Modeling</span>
                                    <span class="badge rounded-pill bg-primary">Machine Learning</span>
                                </div>
                                <hr>
                                <p>This project applies ML and statistical modeling to analyze the dynamics of state repression and citizen mobilization during Bangladesh's July Revolution. One paper from this work is already under review.</p>
                                <div>
                                    <a href="https://arxiv.org/abs/2510.06264" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt me-1"></i> Preprint</a>
                                    <a href="https://github.com/Saiful185/July-Revolution-Analysis" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github me-1"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="card mb-4">
                    <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="AudioFuse.png" class="img-fluid rounded" alt="AudioFuse Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">BIOML Lab</span>
                                <h4 class="card-title text-primary">Multi-Modal Fusion of Different Representations of the Signal for Biomedical Audio Analysis</h4>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Audio and Speech Processing</span>
                                    <span class="badge rounded-pill bg-primary me-1">Deep Learning</span>
                                    <span class="badge rounded-pill bg-primary">Multi-Modal Learning</span>
                                </div>
                                <hr>
                                <p>This project explores advanced fusion techniques for biomedical audio signals. The research aims to combine different signal representations, including waveforms, spectrograms, and scalograms, to build more robust diagnostic models. One paper from this research is currently under review.</p>
                                <div>
                                    <a href="https://arxiv.org/abs/2509.23454" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt me-1"></i> Preprint</a>
                                    <a href="https://github.com/Saiful185/AudioFuse" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github me-1"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="card mb-5">
                    <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="AMR.JPG" class="img-fluid rounded" alt="AMR Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">BIOML Lab</span>
                                <h4 class="card-title text-primary">Fusing Sequence Motifs and Pan-Genomic Features for Antimicrobial Resistance (AMR) Prediction Leveraging Deep Learning & Explainable AI</h4>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Bioinformatics</span>
                                    <span class="badge rounded-pill bg-primary me-1">Explainable AI</span>
                                    <span class="badge rounded-pill bg-primary me-1">Genomics</span>
                                    <span class="badge rounded-pill bg-primary">Ensemble Learning</span>
                                </div>
                                <hr>
                                <p>This research builds upon our accepted paper on AMR prediction. The current focus is on investigating sophisticated feature fusion approaches to improve predictive accuracy, moving beyond the soft-voting ensemble methods used previously.</p>
                                <div>
                                    <a href="https://www.biorxiv.org/content/early/2025/09/27/2025.09.27.678993" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt me-1"></i> Paper</a>
                                    <a href="https://github.com/Saiful185/AMR-EnsembleNet" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github me-1"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                
                <!-- Research Experience -->
                <h3 class="text-center mb-4">Research Experience</h3>
                <div class="card mb-3">
                    <div class="card-body">
                        <div class="d-flex justify-content-between">
                            <h4 class="card-title text-primary">Research Assistant</h4>
                            <span class="badge bg-primary rounded-pill align-self-start">Feb - Aug 2022</span>
                        </div>
                        <h5 class="mb-3">Center for Computational and Data Sciences (CCDS), IUB</h5>
                        <ul>
                            <li>Investigated ML-based methods of Fetal ECG Separation.</li>
                            <li>Contributed to a Graph Neural Networks (GNN) study group.</li>
                        </ul>
                        <a href="https://ccds.ai/" class="btn btn-outline-primary btn-sm" target="_blank">CCDS Homepage</a>
                        <a href="https://drive.google.com/file/d/1JpWXlJMzJZzlKNcEYj8Ir-0FASWLbAyY/view?usp=sharing" class="btn btn-outline-primary btn-sm ms-2" target="_blank">Experience Certificate</a>
                    </div>
                </div>
                <div class="card mb-5">
                    <div class="card-body">
                        <div class="d-flex justify-content-between">
                            <h4 class="card-title text-primary">Co-founder & Researcher</h4>
                            <span class="badge bg-primary rounded-pill align-self-start">2025 - Present</span>
                        </div>
                        <h5 class="mb-3">BIOML (Bioinformatics, Imaging & Omics using Machine Learning) Lab</h5>
                        <ul>
                            <li>Co-founded a collaborative research group of young researchers from Bangladesh.</li>
                            <li>Focus on ML applications in bioinformatics, biomedical imaging, and omics.</li>
                        </ul>
                        <a href="#" class="btn btn-outline-primary btn-sm disabled" aria-disabled="true">Homepage (Coming Soon)</a>
                    </div>
                </div>

                <!-- Grants -->
                <h3 class="text-center mb-4">Research Grants</h3>
                <div class="card mb-5">
                    <div class="card-body">
                        <div class="d-flex justify-content-between">
                            <h4 class="card-title text-primary">Co-Principal Investigator</h4>
                            <span class="badge bg-primary rounded-pill align-self-start">2023 – 2025</span>
                        </div>
                        <h5 class="mb-3">UIU Research Grant, Institute for Advanced Research (IAR)</h5>
                        <ul>
                            <li><strong>Project Title:</strong> “Training Sets vs Training Subsets: Another Method to Reduce Overfitting?”</li>
                            <li><strong>Grant Amount:</strong> BDT 4,90,000</li>
                        </ul>
                        <a href="https://iar.uiu.ac.bd/" class="btn btn-outline-primary btn-sm" target="_blank">IAR Homepage</a>
                    </div>
                </div>

                <!-- Mentorship -->
                <h3 class="text-center mb-4">Mentorship and Supervision</h3>
                <div class="card">
                     <div class="card-body">
                        <p>Supervised or currently supervising 72 students for their undergraduate dissertations, primarily in the fields of Medical Imaging, Bioinformatics, and Health Informatics.</p>
                        <hr>
                        <h5 class="mt-3">Example Supervised Thesis:</h5>
                        <h4 class="card-title text-primary mt-2">Fusion-Based Multimodal Deep Learning to Improve Detection of Diabetic Retinopathy</h4>
                        <p class="card-text">Integrating retinal imaging, clinical data and systemic biomarkers to enhance disease detection.</p>
                        <div class="project-details mt-3">
                            <p class="mb-1"><i class="fas fa-user-tie"></i> Supervisors: Dr. Jannatun Nur Mukta, Md. Saiful Bari Siddiqui</p>
                            <p><i class="fas fa-calendar-alt"></i> Jan '25 - Oct '25</p>
                            <a href="https://drive.google.com/file/d/1fDdF3QnpZwDghEyrrO6i9AwlKDweNIAa/view?usp=sharing" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt me-1"></i> Thesis Report</a>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        
        <!-- Connect Section (Copied from index.html for consistency) -->
        <section id="connect" class="section fade-in">
             <div class="container">
                <h2>Connect</h2>
                <div class="row">
                    <div class="col-12">
                        <div class="insight-card connect text-center">
                            <h4><i class="fas fa-globe"></i> Get in Touch</h4>
                            <p>Find me on academic and professional networks, or reach out via email.</p>
                            <div class="social-links">
                                <a href="https://github.com/Saiful185" class="btn social-btn github" title="GitHub" target="_blank" rel="noopener noreferrer">
                                    <i class="fab fa-github"></i> GitHub
                                </a>
                                <a href="https://scholar.google.com/citations?user=kSXa-48AAAAJ&hl=en" class="btn social-btn scholar" title="Google Scholar" target="_blank" rel="noopener noreferrer">
                                    <i class="fas fa-graduation-cap"></i> Google Scholar
                                </a>
                                <a href="https://www.youtube.com/@saifulbariiftu/playlists" class="btn social-btn youtube" title="YouTube" target="_blank" rel="noopener noreferrer">
                                    <i class="fab fa-youtube"></i> YouTube
                                </a>
                            </div>
                            <div class="contact-info mt-4">
                                <p><i class="fas fa-envelope"></i> <a href="mailto:saiful.bari@bracu.ac.bd">saiful.bari@bracu.ac.bd</a></p>
                                <p><i class="fas fa-map-marker-alt"></i>North Badda, Dhaka-1212, Bangladesh</p>
                                <p><i class="fas fa-phone"></i> +880-1758805835</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
    </main>
    
    <!-- Footer -->
    <footer class="text-center">
        <div class="container">
            <p>&copy; 2025 Md. Saiful Bari Siddiqui. All rights reserved.</p>
        </div>
    </footer>

    <!-- JS Scripts (Same as index.html) -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <script>
        const fadeElements = document.querySelectorAll('.fade-in');
        const observer = new IntersectionObserver(entries => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('visible');
                }
            });
        });
        fadeElements.forEach(element => {
            observer.observe(element);
        });
    </script>
<!-- Dark Mode Toggle & Persistence Script -->
<script>
    const themeToggle = document.getElementById('theme-toggle');
    const body = document.body;
    const icon = themeToggle.querySelector('i');

    // Function to apply the saved theme on page load
    const applyTheme = () => {
        const savedTheme = localStorage.getItem('theme');
        if (savedTheme === 'dark') {
            body.classList.add('dark-mode');
            icon.className = 'fas fa-sun';
        } else {
            body.classList.remove('dark-mode');
            icon.className = 'fas fa-moon';
        }
    };

    // Event listener for the toggle button
    themeToggle.addEventListener('click', () => {
        body.classList.toggle('dark-mode');
        // Save the theme preference to localStorage
        if (body.classList.contains('dark-mode')) {
            localStorage.setItem('theme', 'dark');
            icon.className = 'fas fa-sun';
        } else {
            localStorage.setItem('theme', 'light');
            icon.className = 'fas fa-moon';
        }
    });

    // Apply the theme when the DOM is fully loaded
    document.addEventListener('DOMContentLoaded', applyTheme);
</script>
</body>
</html>
