<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>M. S. B. Siddiqui - Research</title>
    <!-- CSS Links etc. -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <!-- Final Navigation Bar -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top">
        <div class="container">
            <a class="navbar-brand" href="index.html">M. S. B. Siddiqui</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item"><a class="nav-link" href="index.html">About</a></li>
                    <li class="nav-item"><a class="nav-link active" href="research.html">Research</a></li>
                    <li class="nav-item"><a class="nav-link" href="publications.html">Publications</a></li>
                    <li class="nav-item"><a class="nav-link" href="teaching.html">Teaching</a></li>
                    <li class="nav-item"><a class="nav-link" href="experience.html">Experience</a></li>
                    <li class="nav-item"><a class="nav-link" href="qualifications.html">Credentials</a></li>
                    <li class="nav-item"><a class="nav-link" href="awards.html">Awards</a></li>
                    <li class="nav-item"><a class="nav-link" href="others.html">Others</a></li>
                </ul>
                <button id="theme-toggle" class="btn theme-toggle-btn ms-2">
                    <i class="fas fa-moon"></i>
                </button>
            </div>
        </div>
    </nav>

    <!-- Main Content -->
    <main>
        <section id="research" class="section fade-in">
            <div class="container">
                <h2 class="mb-5">Research</h2>

                <!-- Research Statement -->
                <h3 class="text-center mb-4">Research Statement</h3>
                <div style="text-align: justify;">
                    <p class="lead">My research is centered at the intersection of Deep Learning, Signal Processing, and Computer Vision, with a primary focus on developing ML-based solutions for Healthcare and Diagnostics. I am driven by the challenge of integrating information from multiple domains, signal representations, or modalities to build models that are efficient, generalizable, and interpretable.</p>
                    <p>In my undergraduate engineering studies, Signal Processing was something I really started to enjoy. To me, the frequency domain was a whole new universe, and that fascination is still intact. Later, I got to explored Machine Learning, and soon I knew I had found my core interest. To bridge these two worlds, I consciously chose to enroll in two simultaneous MS programs (in EE and CS), allowing me to solidify my understanding of core DL and also explore its applications in Signal and Image Processing.</p>
                    <p>Due to this multidisciplinary background, I have quite a wide range of research interests, spanning from Multi-Modal Machine Learning & Deep Learning Architectures, to their applications in Biomedical Imaging, Signal Processing, Bioinformatics and even Computational Social Science. My research (currently) focuses on effectively fusing features learned from two complementary domains: the time/spatial domain (like a raw audio waveform or an image) and the frequency/spectral domain (its Fourier transform or spectrogram). The goal is to build models that learn from both domains and, as a result, are more efficient and robust, gaining a richer, more holistic view of the data. I've actively explored this "dual-domain" approach in several areas, including Biomedical Imaging (fusing images with their FFTs) and Audio Analysis (combining raw waveforms with spectrograms).</p>
                    <p>I enjoy designing and extensively tweaking Deep Learning architectures, and following theoretically grounded intuitions while doing so (even though intuition doesn't always work with neural networks!). I am also interested in more theoretical aspects of Deep Learning, like Generalization, and worked on it for my MS thesis. As someone who is passionate about politics and social justice, another interest of mine is applying computational methods to analyze complex socio-political systems. I have already worked on a quantitative analysis of the July Revolution, a pivotal event in Bangladesh’s history that I have followed intensely and have been a part of.</p>
                    <p>I recently co-founded <strong>BIOML (Bioinformatics, Imaging & Omics using Machine Learning)</strong>, a collaborative of young researchers from Bangladesh. Some of our current projects include developing advanced methods for Antimicrobial Resistance (AMR) prediction, creating interpretable approaches for physiological signal-based diagnostics, and designing novel deep learning frameworks for medical imaging and audio analysis. The ultimate goal is to build intelligent tools that have a tangible impact on real-world challenges.</p>
                    <p>If any of this sounds interesting, or if you'd like to collaborate, please feel free to send me an email!</p>
                </div>
                <hr class="my-5">

                <!-- Research Interests -->
                <h3 class="text-center mb-4">Research Interests</h3>
                <div class="row mb-5">
                    <div class="col-md-6">
                        <ul class="list-unstyled specializations">
                            <li><i class="fas fa-project-diagram"></i> Multi-Modal Machine Learning</li>
                            <li><i class="fas fa-brain"></i> Deep Learning Architectures</li>
                            <li><i class="fas fa-wave-square"></i> Signal & Image Processing</li>
                            <li><i class="fas fa-microphone-alt"></i> Audio and Speech Processing</li>
                            <li><i class="fas fa-sitemap"></i> Federated Learning</li>
                        </ul>
                    </div>
                    <div class="col-md-6">
                        <ul class="list-unstyled specializations">
                            <li><i class="fas fa-eye"></i> Computer Vision and Medical Imaging</li>
                            <li><i class="fas fa-dna"></i> Bioinformatics</li>
                            <li><i class="fas fa-heartbeat"></i> AI in Healthcare</li>
                            <li><i class="fas fa-landmark"></i> Computational Social Science</li>
                            <li><i class="fas fa-microscope"></i> Explainable AI</li>
                        </ul>
                    </div>
                </div>
                <hr class="my-5">

                <!-- Thesis Projects -->
                <h3 class="text-center mb-4">Thesis Projects</h3>
                <div class="card mb-4">
                    <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="DUA_D2C.png" class="img-fluid rounded" alt="D2C Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">M.Sc. Thesis (CSE)</span>
                                <h4 class="card-title text-primary">Divide2Conquer (D2C) & Dynamic Uncertainty Aware Divide2Conquer (DUA-D2C): Overfitting Remediation in Deep Learning Using a Decentralized Approach</h4>
                                <p class="text-muted"><strong>Supervisor:</strong> Prof. Dr. Golam Rabiul Alam</p>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Deep Learning</span>
                                    <span class="badge rounded-pill bg-primary">Overfitting</span>
                                    <span class="badge rounded-pill bg-primary">Optimization</span>
                                </div>
                                <hr>
                                <p><strong>Part 1 (Divide2Conquer):</strong> Introduced the Divide2Conquer (D2C) method, which partitions training data to train identical models independently on each subset, aggregating parameters periodically to limit the impact of individual outliers/noise and mitigate overfitting. Published at IEEE BigData 2024.</p>
                                <div class="mb-3">
                                    <a href="https://doi.org/10.1109/BigData62323.2024.10826082" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt me-1"></i> Paper</a>
                                    <a href="https://github.com/Saiful185/Divide2Conquer" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github me-1"></i> Code</a>
                                </div>
                                <p><strong>Part 2 (DUA-D2C):</strong> Extended D2C to develop Dynamic Uncertainty-Aware D2C (DUA-D2C), an enhancement that dynamically weights edge models based on performance and prediction uncertainty, further improving robustness. Currently under review.</p>
                                <div>
                                    <a href="https://arxiv.org/abs/2411.15876" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt me-1"></i> Preprint</a>
                                    <a href="https://github.com/Saiful185/DUA-D2C" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github me-1"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="card mb-4">
                     <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="S3FNet_SN1.png" class="img-fluid rounded" alt="S3F-Net Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">M.Sc. Thesis (EEE)</span>
                                <h4 class="card-title text-primary">Medical Image Segmentation & Classification based on a Dual-Domain Approach of Spatial and Spectral Feature Fusion</h4>
                                <p class="text-muted"><strong>Supervisor:</strong> Prof. Dr. Mohammed Imamul Hassan Bhuiyan</p>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Computer Vision</span>
                                    <span class="badge rounded-pill bg-primary me-1">Biomedical Imaging</span>
                                    <span class="badge rounded-pill bg-primary">Representation Learning</span>
                                    <span class="badge rounded-pill bg-primary">Multi-Modal Fusion</span>
                                </div>
                                <hr>
                                <p><strong>Part 1 (S³F-Net):</strong> Proposed S³F-Net, a dual-branch framework that learns from both spatial (CNN) and spectral (SpectraNet) domains simultaneously, achieving performance improvements over unimodal baselines & state-of-the-art competitive accuracy on multiple medical imaging datasets.</p>
                                <div class="mb-3">
                                    <a href="https://arxiv.org/abs/2509.23442" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt me-1"></i> Preprint</a>
                                    <a href="https://github.com/Saiful185/S3F-Net" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github me-1"></i> Code</a>
                                </div>
                                <p><strong>Part 2 (Spatio-Spectral Medical Image Segmentation):</strong> Currently extending the S³F-Net architecture to perform robust and accurate segmentation tasks on medical images, leveraging its multi-domain feature learning capabilities.</p>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="card mb-5">
                     <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="BRL_RF.JPG" class="img-fluid rounded" alt="BRL Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">B.Sc. Thesis (EEE)</span>
                                <h4 class="card-title text-primary">Bioradiolocation-Based Multi-Class Sleep Stage Classification</h4>
                                <p class="text-muted"><strong>Supervisor:</strong> Prof. Dr. Mohammed Imamul Hassan Bhuiyan</p>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Biomedical Signal Processing</span>
                                    <span class="badge rounded-pill bg-primary">Machine Learning</span>
                                </div>
                                <hr>
                                <p>This undergraduate thesis focused on a non-invasive sleep stage classification method using bioradiolocation signals. By extensively extracting time & frequency domain features and employing a Random Forest classifier, the system outperformed state-of-the-art methods in terms of several metrics. Published at ICECE 2022.</p>
                                <div>
                                    <a href="https://doi.org/10.1109/ICECE57408.2022.10089093" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt me-1"></i> Paper</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Ongoing Research Projects -->
                <h3 class="text-center mb-4">Ongoing Research Projects</h3>
                <div class="card mb-4">
                     <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="July_Revolution.JPG" class="img-fluid rounded" alt="July Revolution Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">Collaboration with University of Oxford</span>
                                <h4 class="card-title text-primary">Machine Learning & Statistical Modeling Driven Repression and Mobilization Analysis of Bangladesh's Social Movements</h4>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Computational Social Science</span>
                                    <span class="badge rounded-pill bg-primary">Statistical Modeling</span>
                                    <span class="badge rounded-pill bg-primary">Machine Learning</span>
                                </div>
                                <hr>
                                <p>This project applies ML and statistical modeling to analyze the dynamics of state repression and citizen mobilization during Bangladesh's recent social movements. One paper from this work focusing on July Revolution is already under review.</p>
                                <div>
                                    <a href="https://arxiv.org/abs/2510.06264" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt me-1"></i> Preprint</a>
                                    <a href="https://github.com/Saiful185/July-Revolution-Analysis" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github me-1"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="card mb-4">
                    <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="AudioFuse.png" class="img-fluid rounded" alt="AudioFuse Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">BIOML Lab</span>
                                <h4 class="card-title text-primary">Multi-Modal Fusion of Different Representations of the Signal for Biomedical Audio Analysis</h4>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Audio and Speech Processing</span>
                                    <span class="badge rounded-pill bg-primary me-1">Deep Learning</span>
                                    <span class="badge rounded-pill bg-primary">Multi-Modal Learning</span>
                                </div>
                                <hr>
                                <p>This project explores fusion of features learned from different representations of biomedical audio signals, to exploit the complementary strengths of each representation. We explored different representations including waveforms, spectrograms, and scalograms for robust diagnostic models, and one paper from this research is currently under review.</p>
                                <div>
                                    <a href="https://arxiv.org/abs/2509.23454" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt me-1"></i> Preprint</a>
                                    <a href="https://github.com/Saiful185/AudioFuse" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github me-1"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="card mb-5">
                    <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="AMR.JPG" class="img-fluid rounded" alt="AMR Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">BIOML Lab</span>
                                <h4 class="card-title text-primary">Antimicrobial Resistance (AMR) Prediction from Genomic Data (SNPs) Leveraging Deep Learning & Explainable AI</h4>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Bioinformatics</span>
                                    <span class="badge rounded-pill bg-primary me-1">Explainable AI</span>
                                    <span class="badge rounded-pill bg-primary me-1">Genomics</span>
                                    <span class="badge rounded-pill bg-primary">Ensemble Learning</span>
                                </div>
                                <hr>
                                <p>This research exploits different perspectives provided by different types of models. We explored the utility of the sequential information available in SNPs through sequence-aware models and currently investigating fusion mechanisms to combine them with "bag-of features" models. We also incorporate Explainable-AI methods to biologically validate our models, by mapping the SNP positions to the corresponding genes and investigating their relevance in AMR. One paper from this research has been accepted at SCA/HPCAsia 2026.</p>
                                <div>
                                    <a href="https://www.biorxiv.org/content/early/2025/09/27/2025.09.27.678993" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt me-1"></i> Paper</a>
                                    <a href="https://github.com/Saiful185/AMR-EnsembleNet" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github me-1"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                
                <!-- Research Experience -->
                <h3 class="text-center mb-4">Research Experience</h3>
                <div class="card mb-3">
                    <div class="card-body">
                        <div class="d-flex justify-content-between">
                            <h4 class="card-title text-primary">Research Assistant</h4>
                            <span class="badge bg-primary rounded-pill align-self-start">Feb - Aug 2022</span>
                        </div>
                        <h5 class="mb-3">Center for Computational and Data Sciences (CCDS), IUB</h5>
                        <ul>
                            <li>Investigated ML-based methods of Fetal ECG Separation.</li>
                            <li>Contributed to the Graph Neural Networks (GNN) study group.</li>
                        </ul>
                        <a href="https://ccds.ai/" class="btn btn-outline-primary btn-sm" target="_blank">CCDS Homepage</a>
                        <a href="https://drive.google.com/file/d/1JpWXlJMzJZzlKNcEYj8Ir-0FASWLbAyY/view?usp=sharing" class="btn btn-outline-primary btn-sm ms-2" target="_blank">Experience Certificate</a>
                    </div>
                </div>
                <div class="card mb-5">
                    <div class="card-body">
                        <div class="d-flex justify-content-between">
                            <h4 class="card-title text-primary">Co-founder & Researcher</h4>
                            <span class="badge bg-primary rounded-pill align-self-start">2025 - Present</span>
                        </div>
                        <h5 class="mb-3">BIOML (Bioinformatics, Imaging & Omics using Machine Learning) Lab</h5>
                        <ul>
                            <li>Co-founded a collaborative research group of young researchers from Bangladesh.</li>
                            <li>Focus on ML applications in bioinformatics, biomedical imaging, biomedical signal processing, and omics.</li>
                        </ul>
                        <a href="#" class="btn btn-outline-primary btn-sm disabled" aria-disabled="true">Homepage (Coming Soon)</a>
                    </div>
                </div>

                <!-- Grants -->
                <h3 class="text-center mb-4">Research Grants</h3>
                <div class="card mb-5">
                    <div class="card-body">
                        <div class="d-flex justify-content-between">
                            <h4 class="card-title text-primary">Co-Principal Investigator</h4>
                            <span class="badge bg-primary rounded-pill align-self-start">2023 – 2025</span>
                        </div>
                        <h5 class="mb-3">UIU Research Grant, Institute for Advanced Research (IAR)</h5>
                        <ul>
                            <li><strong>Project Title:</strong> “Training Sets vs Training Subsets: Another Method to Reduce Overfitting?”</li>
                            <li><strong>Grant Amount:</strong> BDT 4,90,000</li>
                        </ul>
                        <a href="https://iar.uiu.ac.bd/" class="btn btn-outline-primary btn-sm" target="_blank">IAR Homepage</a>
                    </div>
                </div>

                <!-- Mentorship -->
                <h3 class="text-center mb-4">Mentorship and Supervision</h3>
                <div class="card">
                     <div class="card-body">
                        <p>Supervised or currently supervising 72 students for their undergraduate dissertations, primarily in the fields of Medical Imaging, Bioinformatics, and Health Informatics.</p>
                        <hr>
                        <h5 class="mt-3">Example Supervised Thesis:</h5>
                        <h4 class="card-title text-primary mt-2">Fusion-Based Multimodal Deep Learning to Improve Detection of Diabetic Retinopathy</h4>
                        <p class="card-text">Integrating retinal imaging, clinical data and systemic biomarkers to enhance disease detection.</p>
                        <div class="project-details mt-3">
                            <p class="mb-1"><i class="fas fa-user-tie"></i> Supervisors: Dr. Jannatun Nur Mukta, Md. Saiful Bari Siddiqui</p>
                            <p><i class="fas fa-calendar-alt"></i> Jan '25 - Oct '25</p>
                            <a href="https://drive.google.com/file/d/1fDdF3QnpZwDghEyrrO6i9AwlKDweNIAa/view?usp=sharing" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt me-1"></i> Thesis Report</a>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        
        <!-- Connect Section (Copied from index.html for consistency) -->
        <section id="connect" class="section fade-in">
             <div class="container">
                <h2>Connect</h2>
                <div class="row">
                    <div class="col-12">
                        <div class="insight-card connect text-center">
                            <h4><i class="fas fa-globe"></i> Get in Touch</h4>
                            <p>Find me on academic and professional networks, or reach out via email.</p>
                            <div class="social-links">
                                <a href="https://github.com/Saiful185" class="btn social-btn github" title="GitHub" target="_blank" rel="noopener noreferrer">
                                    <i class="fab fa-github"></i> GitHub
                                </a>
                                <a href="https://scholar.google.com/citations?user=kSXa-48AAAAJ&hl=en" class="btn social-btn scholar" title="Google Scholar" target="_blank" rel="noopener noreferrer">
                                    <i class="fas fa-graduation-cap"></i> Google Scholar
                                </a>
                                <a href="https://www.youtube.com/@saifulbariiftu/playlists" class="btn social-btn youtube" title="YouTube" target="_blank" rel="noopener noreferrer">
                                    <i class="fab fa-youtube"></i> YouTube
                                </a>
                            </div>
                            <div class="contact-info mt-4">
                                <p><i class="fas fa-envelope"></i> <a href="mailto:saiful.bari@bracu.ac.bd">saiful.bari@bracu.ac.bd</a></p>
                                <p><i class="fas fa-map-marker-alt"></i>North Badda, Dhaka-1212, Bangladesh</p>
                                <p><i class="fas fa-phone"></i> +880-1758805835</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
    </main>
    
    <!-- Footer -->
    <footer class="text-center">
        <div class="container">
            <p>&copy; 2025 Md. Saiful Bari Siddiqui. All rights reserved.</p>
        </div>
    </footer>

    <!-- JS Scripts (Same as index.html) -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <script>
        const fadeElements = document.querySelectorAll('.fade-in');
        const observer = new IntersectionObserver(entries => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('visible');
                }
            });
        });
        fadeElements.forEach(element => {
            observer.observe(element);
        });
    </script>
<!-- Dark Mode Toggle & Persistence Script -->
<script>
    const themeToggle = document.getElementById('theme-toggle');
    const body = document.body;
    const icon = themeToggle.querySelector('i');

    // Function to apply the saved theme on page load
    const applyTheme = () => {
        const savedTheme = localStorage.getItem('theme');
        if (savedTheme === 'dark') {
            body.classList.add('dark-mode');
            icon.className = 'fas fa-sun';
        } else {
            body.classList.remove('dark-mode');
            icon.className = 'fas fa-moon';
        }
    };

    // Event listener for the toggle button
    themeToggle.addEventListener('click', () => {
        body.classList.toggle('dark-mode');
        // Save the theme preference to localStorage
        if (body.classList.contains('dark-mode')) {
            localStorage.setItem('theme', 'dark');
            icon.className = 'fas fa-sun';
        } else {
            localStorage.setItem('theme', 'light');
            icon.className = 'fas fa-moon';
        }
    });

    // Apply the theme when the DOM is fully loaded
    document.addEventListener('DOMContentLoaded', applyTheme);
</script>
</body>
</html>
